{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **IMPORTS**"
      ],
      "metadata": {
        "id": "UXyJUwDPmWGk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ud9JFXPGNOuF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **DATA LOADING**\n"
      ],
      "metadata": {
        "id": "8zIOKKIGmglu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to the file you'd like to load\n",
        "file_path = \"lung_cancer_dataset.csv\"\n",
        "\n",
        "# Load the latest version\n",
        "df = kagglehub.dataset_load(\n",
        "   KaggleDatasetAdapter.PANDAS,\n",
        "  \"mikeytracegod/lung-cancer-risk-dataset\",\n",
        "  path = file_path\n",
        ")\n",
        "\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "BpKdoHuHNeuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **DATA WRANGLING**\n",
        "\n",
        "First, we need to do some quick preprocessing."
      ],
      "metadata": {
        "id": "LBsAVXoul2vB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical variables to quantitative\n",
        "df['lung_cancer'] = df['lung_cancer'].map({'Yes': 1, 'No': 0})\n",
        "df['gender'] = df['gender'].map({'Male': 1, 'Female': 0})\n",
        "df['radon_exposure'] = df['radon_exposure'].map({'Low': 0, 'Medium': 1, 'High': 2})\n",
        "df['asbestos_exposure'] = df['asbestos_exposure'].map({'Yes': 1, 'No': 0})\n",
        "df['secondhand_smoke_exposure'] = df['secondhand_smoke_exposure'].map({'Yes': 1, 'No': 0})\n",
        "df['copd_diagnosis'] = df['copd_diagnosis'].map({'Yes': 1, 'No': 0})\n",
        "df['alcohol_consumption'] = df['alcohol_consumption'].map({np.nan: 0, 'Moderate': 1, 'Heavy': 2})\n",
        "df['family_history'] = df['family_history'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "RKeOTseKfWIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will do our train/test split and build the model."
      ],
      "metadata": {
        "id": "GI05euWTl6Wy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make features every variable except our response (lung_cancer)\n",
        "features = [col for col in df.columns if col != \"lung_cancer\" and col != \"patient_id\"]\n",
        "\n",
        "# Train/test split\n",
        "train_x, test_x, train_y, test_y = train_test_split(df[features], df[\"lung_cancer\"], random_state=1)\n",
        "\n",
        "# Building and fitting model\n",
        "clf = RandomForestClassifier(n_estimators=200, random_state=1)\n",
        "mymodel = clf.fit(train_x, train_y)"
      ],
      "metadata": {
        "id": "LiLDLPU8gMZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **PERMUTATION IMPORTANCE (PIMP)**\n",
        "\n",
        "Before we calculate the permutation importance for every feature, I want to show how it works manually for one feature."
      ],
      "metadata": {
        "id": "SHgi1dfRmBVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_acc = accuracy_score(test_y, clf.predict(test_x))\n",
        "base_acc"
      ],
      "metadata": {
        "id": "hFEQzpMslx_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a copy\n",
        "permuted_x = test_x.copy()\n",
        "permuted_x.head(3)"
      ],
      "metadata": {
        "id": "A3uc-C-LwFH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the 'pack years' feature\n",
        "np.random.shuffle(permuted_x['pack_years'].values)\n",
        "\n",
        "permuted_x.head(3)"
      ],
      "metadata": {
        "id": "B1tc1cE8mXCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get accuracy after shuffling\n",
        "permuted_acc = accuracy_score(test_y, clf.predict(permuted_x))\n",
        "print(f\"Permuted accuracy: {permuted_acc}\")\n",
        "# Calculate importance (drop in accuracy)\n",
        "importance = base_acc - permuted_acc\n",
        "print(f\"Permutation importance: {importance:.4f}\")"
      ],
      "metadata": {
        "id": "DHwS_bd_tnXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we'll run the function to compute the importance for every feature."
      ],
      "metadata": {
        "id": "qWGp1luHmyS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline performance\n",
        "y_pred = clf.predict(test_x)\n",
        "baseline_acc = accuracy_score(test_y, y_pred)\n",
        "print(f\"Baseline accuracy: {baseline_acc:.3f}\")\n",
        "\n",
        "# Permutation importance\n",
        "perm = permutation_importance(clf, test_x, test_y, n_repeats=3, scoring='accuracy')\n",
        "imp_df = pd.DataFrame({\n",
        "    'feature': test_x.columns,\n",
        "    'importance_mean': perm.importances_mean,\n",
        "    'importance_std': perm.importances_std\n",
        "}).sort_values('importance_mean', ascending=False)\n",
        "\n",
        "imp_df.head(3)"
      ],
      "metadata": {
        "id": "CyHZAVZmj_CI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make gradient for our table to see better\n",
        "red_white_green = LinearSegmentedColormap.from_list(\"red_white_green\", [\"red\", \"white\", \"green\"])\n",
        "\n",
        "styled_df = imp_df.style.background_gradient(\n",
        "    subset=[\"importance_mean\"],\n",
        "    cmap=red_white_green,\n",
        "    vmin=-abs(imp_df[\"importance_mean\"]).max(),\n",
        "    vmax=abs(imp_df[\"importance_mean\"]).max()\n",
        ")\n",
        "styled_df"
      ],
      "metadata": {
        "id": "P-4Q1yspmuYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The features toward the top are the most important and those toward the bottom are the least important. The column on the right measures how performance varied from one shuffle to the next when repeating. The negative values mean that the shuffled predictions happened to be more accurate than the real data, usually because that feature was not important."
      ],
      "metadata": {
        "id": "csPRxXTUvCQ5"
      }
    }
  ]
}